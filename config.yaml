# model_name: cbow
model_name: skipgram

dataset: WikiText2
data_dir: /home/zzisbeauty/word2vecs/word2vec-pytorch/data/
train_batch_size: 1
val_batch_size: 96
shuffle: True

optimizer: Adam
learning_rate: 0.025
epochs: 5
train_steps: 
val_steps: 

checkpoint_frequency: 
model_dir: /home/zzisbeauty/word2vecs/word2vec-pytorch/weights/cbow_WikiText2
